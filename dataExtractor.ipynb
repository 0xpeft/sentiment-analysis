{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/thyag/Downloads/intershala assignment/Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title not found for article 13\n",
      "Main content div not found. 13\n",
      "Title not found for article 19\n",
      "Main content div not found. 19\n",
      "Title not found for article 28\n",
      "Main content div not found. 28\n",
      "Title not found for article 35\n",
      "Main content div not found. 35\n",
      "Title not found for article 42\n",
      "Main content div not found. 42\n",
      "Title not found for article 48\n",
      "Main content div not found. 48\n",
      "Title not found for article 82\n",
      "Main content div not found. 82\n",
      "Title not found for article 83\n",
      "Main content div not found. 83\n",
      "Title not found for article 91\n",
      "Main content div not found. 91\n",
      "Title not found for article 98\n",
      "Main content div not found. 98\n",
      "Title not found for article 99\n",
      "Main content div not found. 99\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "      # URL of the webpage\n",
    "    url = df['URL'][i]  # Replace with the actual URL\n",
    "    url_id = df['URL_ID'][i]  # Replace with the actual URL ID\n",
    "\n",
    "\n",
    "    # Send an HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Extract the title\n",
    "    title_element = soup.find(\"h1\", class_=\"entry-title\")\n",
    "    if title_element:\n",
    "        title = title_element.text\n",
    "    else:\n",
    "        print(\"Title not found for article\", i)\n",
    "\n",
    "    # Find the div with class=\"td-post-content\"\n",
    "    main_content_div = soup.find(\"div\", class_=\"td-post-content tagdiv-type\")\n",
    "\n",
    "    # Extract the text content\n",
    "    if main_content_div:\n",
    "        content_text = main_content_div.get_text()\n",
    "    else:\n",
    "        print(\"Main content div not found.\",  i)\n",
    "\n",
    "    output_directory = \"/Users/thyag/Downloads/intershala assignment/testFiles\"  # Replace with the actual directory path\n",
    "    output_filename = f\"{output_directory}/{url_id}.txt\"\n",
    "\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Title: {title}\\n\\n\")\n",
    "        file.write(content_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
